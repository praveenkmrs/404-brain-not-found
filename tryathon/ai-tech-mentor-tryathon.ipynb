{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a33d50ea-2163-4372-ae99-2d947893b269",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Dependencies"
    }
   },
   "outputs": [],
   "source": [
    "# %pip install langchain\n",
    "# %pip install langchain-openai\n",
    "# %pip install openai==1.56.2\n",
    "# %pip install azure-identity==1.19.0\n",
    "# %pip install pydantic==2.9.2\n",
    "# %pip install requests\n",
    "# %pip install python-dotenv\n",
    "# %pip install repomix\n",
    "# %pip install beautifulsoup4\n",
    "# %pip install mlflow\n",
    "\n",
    "# dbutils.library.restartPython()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b5225e8e-da19-4db4-8905-33ca0b869520",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "OpenAI client"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from openai import AzureOpenAI\n",
    "from azure.identity import ClientSecretCredential\n",
    "######## Boilerplate necessary to make things work in OneLab/OpenLab ########\n",
    "LAB_VARIANT = \"OpenLab\" # USE \"OneLab\" IF YOU'RE USING ONELAB\n",
    "ENVIRONMENT = \"prd\" # choose ENVIRONMENT as dev, uat or prd based on environment\n",
    "def get_openai_urls(lab_variant: str):\n",
    "  \"\"\"This function is created to return OpenAI URLs for OpenLab/OneLab. We want to use the function with lazy evaluation so that OneLab doesn't affect OpenLab and vice-versa.\"\"\"\n",
    "  if lab_variant == \"OpenLab\":\n",
    "    secret_scope = f\"{lab_variant}-SecretScope\"\n",
    "    return f\"https://{dbutils.secrets.get(scope=secret_scope, key='OpenAiHostname')}openoaisdc-completions-apis/\"\n",
    "  elif lab_variant == \"OneLab\":\n",
    "    return f\"https://apim-1labgen-ap-apizone-{ENVIRONMENT}01.azure-api.net/openaisdc-completions-apis/\"\n",
    "  else: \n",
    "    raise Exception(\"Invalid lab_variant\")\n",
    "\n",
    "client_id = dbutils.secrets.get(scope=f\"{LAB_VARIANT}-SecretScope\", key=\"DataServicePrincipalClientId\")\n",
    "client_secret = dbutils.secrets.get(scope=f\"{LAB_VARIANT}-SecretScope\", key=\"DataServicePrincipalClientSecret\")\n",
    "credential = ClientSecretCredential(tenant_id=\"6e93a626-8aca-4dc1-9191-ce291b4b75a1\", client_id=client_id, client_secret=client_secret)\n",
    "access_token = credential.get_token(\"https://cognitiveservices.azure.com/.default\")\n",
    "\n",
    "os.environ[\"AZURE_OPENAI_TOKEN\"] = access_token.token\n",
    "os.environ[\"AZURE_OPENAI_VERSION\"] = \"2024-10-21\"  # https://learn.microsoft.com/en-us/azure/ai-services/openai/reference#api-specs\n",
    "os.environ[\"AZURE_OPENAI_BASE_URL\"] = get_openai_urls(LAB_VARIANT)\n",
    "os.environ[\"USER_AGENT\"] = \"myagent\"\n",
    "\n",
    "client = AzureOpenAI(\n",
    "  api_key=os.environ[\"AZURE_OPENAI_TOKEN\"],  \n",
    "  api_version=os.environ[\"AZURE_OPENAI_VERSION\"],\n",
    "  azure_endpoint=os.environ[\"AZURE_OPENAI_BASE_URL\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e8b2cfd0-8b1b-4de4-8a5a-14cb71e93621",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Init MLFLOW"
    }
   },
   "outputs": [],
   "source": [
    "import mlflow\n",
    "mlflow.openai.autolog()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "faa2366c-e515-4fa0-92d5-2bb7c4fcfb04",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "__________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ee739e32-6022-46ee-9edd-fbccd04d2ccb",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Utils: openAI chat client call"
    }
   },
   "outputs": [],
   "source": [
    "def get_completion_without_rag(query: str, context: str, model: str = \"gpt-5\") -> str:\n",
    "      completion = client.chat.completions.create(\n",
    "        model=model, # gpt-4o, gpt-4.1, gpt-5\n",
    "        messages=[\n",
    "          {\"role\": \"system\", \"content\": context}, # <-- This is the system message that provides context to the model\n",
    "          {\"role\": \"user\", \"content\": query}  # <-- This is the user message for which the model will generate a response\n",
    "        ],\n",
    "        seed=1\n",
    "      )\n",
    "      return completion.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2e0b796a-bf43-4819-b931-85aa2a74fc03",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Utils: sanitising"
    }
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def remove_html_re(text):\n",
    "    # Remove HTML tags\n",
    "    clean = re.sub(r'<.*?>', '', text)\n",
    "    return clean\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def remove_html(text):\n",
    "    soup = BeautifulSoup(text, \"html.parser\")\n",
    "    return soup.get_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c7d11814-c212-4ed3-bfad-844d4fd47285",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Utils: env load"
    }
   },
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "dotenv_path = '/Workspace/Shared/HACKATHON/TEAM 70/hackathon/404-brain-not-found/tryathon/.env'\n",
    "\n",
    "load_dotenv(dotenv_path=dotenv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "56177cfb-68fe-4359-bec2-cbd6e9efcc67",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Stage1.a: Utils: Fetch source code"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import zipfile\n",
    "import io\n",
    "import shutil\n",
    "\n",
    "def download_repo_zip(repo_url):\n",
    "    repo_name = repo_url.split(\"/\")[-1].replace(\".git\", \"\")\n",
    "    source_dir = os.path.join(os.getcwd(), \"source\")\n",
    "    full_path = os.path.join(source_dir, repo_name)\n",
    "    if os.path.exists(full_path):\n",
    "        shutil.rmtree(full_path)  # Clear the output directory if it exists\n",
    "    os.makedirs(full_path, exist_ok=True)\n",
    "    \n",
    "    if repo_url.endswith(\".git\"):\n",
    "        repo_url = repo_url[:-4]\n",
    "    zip_url = f\"{repo_url}/archive/refs/heads/main.zip\"\n",
    "\n",
    "    # print(f\"Downloading {zip_url} to {full_path}\")\n",
    "    os.makedirs(full_path, exist_ok=True)\n",
    "    response = requests.get(zip_url)\n",
    "    if response.status_code == 200:\n",
    "        with zipfile.ZipFile(io.BytesIO(response.content)) as zip_ref:\n",
    "            zip_ref.extractall(full_path)\n",
    "        # print(f\"Downloaded and extracted to {full_path}\")\n",
    "        return full_path\n",
    "    else:\n",
    "        print(f\"Failed to download repository zip: {response.status_code}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "678d1f5a-5cc4-4c42-8e10-52bb1aa5f58d",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Stage1.b: Download source code"
    }
   },
   "outputs": [],
   "source": [
    "repo_url = \"https://github.com/praveenkmrs/fluffy-parakeet.git\"\n",
    "cloned_repo = download_repo_zip(repo_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "24867150-2809-42bf-ad6e-8157ea64e272",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Stage1.c: Compile source code as single file"
    }
   },
   "outputs": [],
   "source": [
    "from utils.code_parser import parse_codebase\n",
    "\n",
    "result = parse_codebase(codebase_path=cloned_repo)\n",
    "codebase = result.output_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5b8459bb-54e6-454e-a7e0-bcccb757cc3c",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Stage1.d: Fetch issues from the repository"
    }
   },
   "outputs": [],
   "source": [
    "from utils.github_issues_scrapper import get_issues\n",
    "import os\n",
    "\n",
    "token=os.getenv(\"GITHUB_TOKEN\")\n",
    "owner=repo_url.split(\"/\")[-2]\n",
    "repo = repo_url.split(\"/\")[-1].replace(\".git\", \"\")\n",
    "\n",
    "github_issues = get_issues(owner=owner, repo=repo, token=token)\n",
    "\n",
    "issues_str = \"\\n\".join(\n",
    "    f\"- Title: {issue.title}\\n  Body: {remove_html(issue.body)}\\n\"\n",
    "    for issue in github_issues\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "44de5e68-54df-40a2-9349-d41071f5335f",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Stage2.a: User story - Create Prompt with context"
    }
   },
   "outputs": [],
   "source": [
    "prompt_template_po = open(\"prompts/po_prompt.txt\").read()\n",
    "prompt_po = prompt_template_po.format(\n",
    "    codebase_context=codebase,\n",
    "    issues=issues_str,\n",
    "    tech_stack=\"Spring-boot 3, mongodb, Java 21, maven, Docker, Docker-compose\",\n",
    "    constraints=\"security, performance, scalability, maintainability\"\n",
    ")\n",
    "# prompt_po"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ca49fed7-4725-4e7f-8c38-fd1823fbf6d2",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Stage2.b: User story - Interact with LLM to create user stories"
    }
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "start_time = time.perf_counter()\n",
    "user_stories = get_completion_without_rag(\n",
    "    query=\"Create structured user stories based on the issues\",\n",
    "    context=prompt_po,\n",
    "    model=\"gpt-5\" # gpt-4o, gpt-4.1, gpt-5\n",
    ")\n",
    "end_time = time.perf_counter()\n",
    "elapsed_time = end_time - start_time\n",
    "print(f\"Total time taken to create stories: {elapsed_time}s\")\n",
    "# user_stories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "53782f9c-b87f-4445-af10-08112fb4fb3d",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Stage3.a: Implementation plan - Create Prompt with context"
    }
   },
   "outputs": [],
   "source": [
    "prompt_template_dev = open(\"prompts/dev_prompt.txt\").read()\n",
    "prompt_dev = prompt_template_dev.format(\n",
    "    codebase_context=codebase,\n",
    "    user_stories=user_stories,\n",
    "    tech_stack=\"Spring-boot 3, mongodb, Java 21, maven, Docker, Docker-compose\",\n",
    "    constraints=\"security, performance, scalability, maintainability\"\n",
    ")\n",
    "# prompt_dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fbf45ad6-8949-4bf1-82b2-344a02acadfb",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Stage2.b: Implementation plan - Interact with LLM to create implementation plan"
    }
   },
   "outputs": [],
   "source": [
    "start_time = time.perf_counter()\n",
    "plan = get_completion_without_rag(\n",
    "    query=\"Provide detailed implementation instructions for all of the listed user stories strictly referring to the source code\",\n",
    "    context=prompt_dev,\n",
    "    model=\"gpt-4.1\" # gpt-4o, gpt-4.1, gpt-5\n",
    ")\n",
    "end_time = time.perf_counter()\n",
    "elapsed_time = end_time - start_time\n",
    "print(f\"Total time taken to create plans for the stories: {elapsed_time}s\")\n",
    "# plan"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "3"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": -1,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "ai-tech-mentor-tryathon",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
